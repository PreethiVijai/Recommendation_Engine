{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b36c4ac",
   "metadata": {},
   "source": [
    "\n",
    "# Deep Learning for Movie Recommendation\n",
    "In this notebook, I'll build a deep learning model movie recommendations system on the MovieLens 1M dataset.\n",
    "\n",
    "This will be my 3rd attempt doing this.\n",
    "\n",
    "In the 1st attempt, I tried out content-based and memory-based collaboratice filtering, which rely on the calculation of users and movies' similarity scores. As no training or optimization is involved, these are easy to use approaches. But their performance decrease when we have sparse data which hinders scalability of these approaches for most of the real-world problems.\n",
    "In the 2nd attempt, I tried out a matrix factorization model-based collaborative filtering approach called Singular Vector Decomposition, which reduces the dimension of the dataset and gives low-rank approximation of user tastes and preferences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b86e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import math\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.callbacks import Callback, EarlyStopping, ModelCheckpoint\n",
    "from CFModel import CFModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37e12b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "RATINGS_CSV_FILE = 'ratings.csv'\n",
    "MODEL_WEIGHTS_FILE = 'weights.h5'\n",
    "K_FACTORS = 120\n",
    "RNG_SEED = 1446557"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78d9404",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv(RATINGS_CSV_FILE, \n",
    "                      sep='\\t', \n",
    "                      encoding='latin-1', \n",
    "                      usecols=['user_id', 'movie_id', 'user_emb_id', 'movie_emb_id', 'rating'])\n",
    "max_userid = ratings['user_id'].drop_duplicates().max()\n",
    "max_movieid = ratings['movie_id'].drop_duplicates().max()\n",
    "print(len(ratings), 'ratings loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa1bf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Training Set\n",
    "shuffled_ratings = ratings.sample(frac=1., random_state=RNG_SEED)\n",
    "Users = shuffled_ratings['user_emb_id'].values\n",
    "print ('Users:', Users, ', shape =', Users.shape)\n",
    "Movies = shuffled_ratings['movie_emb_id'].values\n",
    "print ('Movies:', Movies, ', shape =', Movies.shape)\n",
    "Ratings = shuffled_ratings['rating'].values\n",
    "print ('Ratings:', Ratings, ', shape =', Ratings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd6b5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CFModel(max_userid, max_movieid, K_FACTORS)\n",
    "model.compile(loss='mse', optimizer='adamax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a9e2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train Model\n",
    "\n",
    "callbacks = [EarlyStopping('val_loss', patience=2), \n",
    "             ModelCheckpoint(MODEL_WEIGHTS_FILE, save_best_only=True)]\n",
    "history = model.fit([Users, Movies], Ratings, epochs=30, validation_split=.1, verbose=2, callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437d4b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = pd.DataFrame({'epoch': [ i + 1 for i in history.epoch ],\n",
    "                     'training': [ math.sqrt(loss) for loss in history.history['loss'] ],\n",
    "                     'validation': [ math.sqrt(loss) for loss in history.history['val_loss'] ]})\n",
    "ax = loss.ix[:,:].plot(x='epoch', figsize={7,10}, grid=True)\n",
    "ax.set_ylabel(\"root mean squared error\")\n",
    "ax.set_ylim([0.0,3.0]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710459e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_val_loss, idx = min((val, idx) for (idx, val) in enumerate(history.history['val_loss']))\n",
    "print 'Minimum RMSE at epoch', '{:d}'.format(idx+1), '=', '{:.4f}'.format(math.sqrt(min_val_loss))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
